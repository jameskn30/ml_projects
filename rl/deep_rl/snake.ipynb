{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from snakegame.game import SnakeGameAI, Direction, Point\n",
    "from collections import deque\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (195983153.py, line 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 80\u001b[0;36m\u001b[0m\n\u001b[0;31m    else;\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "MAX_MEM = 100000\n",
    "BATCH_SIZE = 1000\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_games = 0\n",
    "        self.epsilon = 0 #choose to explore or exploit policy \n",
    "        self.gamme = 0 # discounted factor\n",
    "        self.memory = deque(maxlen = MAX_MEM)\n",
    "        self.model = None #TODO\n",
    "        self.trainer = None #TODO\n",
    "\n",
    "        # TODO: model, trainer\n",
    "\n",
    "    def get_state(self, game: SnakeGameAI):\n",
    "        #There are 11 states in the game of snake, each is a boolean\n",
    "        # [danger sraight, danger right, danger left, \n",
    "        # direction left, right, up, down, \n",
    "        # food left, food right, food up, food down]\n",
    "        head = game.head()\n",
    "        \n",
    "        point_left = Point(head.x - 20, head.y)\n",
    "        point_right = Point(head.x + 20, head.y)\n",
    "        point_up = Point(head.x, head.y - 20)\n",
    "        point_down = Point(head.x, head.y + 20)\n",
    "\n",
    "        # 4 points of direction\n",
    "        dir_left = game.direction == Direction.LEFT\n",
    "        dir_right = game.direction == Direction.RIGHT\n",
    "        dir_up = game.direction == Direction.UP\n",
    "        dir_down = game.direction == Direction.DOWN\n",
    "\n",
    "        state = [\n",
    "            # 3 state for danger state (straight, right, left)\n",
    "            #danger straight\n",
    "           (dir_up and game.is_collision(point_up)) or \n",
    "           (dir_right and game.is_collision(point_right)) or \n",
    "           (dir_down and game.is_collision(point_down)) or\n",
    "           (dir_left and game.is_collision(point_left)),\n",
    "           #danger right, this is relative to the direction of the snake\n",
    "           #but the point should be relative to world\n",
    "           #so danger right when going down is to its left point \n",
    "           (dir_up and game.is_collision(point_right)) or \n",
    "           (dir_right and game.is_collision(point_down)) or \n",
    "           (dir_down and game.is_collision(point_left)) or\n",
    "           (dir_left and game.is_collision(point_up)),\n",
    "           #same principle for danger left\n",
    "           (dir_up and game.is_collision(point_left)) or \n",
    "           (dir_right and game.is_collision(point_up)) or \n",
    "           (dir_down and game.is_collision(point_right)) or\n",
    "           (dir_left and game.is_collision(point_down)),\n",
    "\n",
    "            # 4 dim for move direction\n",
    "            dir_up, \n",
    "            dir_right, \n",
    "            dir_down, \n",
    "            dir_left, \n",
    "\n",
    "            # 4 dim for food location ( relative to the snake head)\n",
    "            # up, right, down, left\n",
    "            game.food.y < game.head.y, #up\n",
    "            game.food.x > game.head.x, #right\n",
    "            game.food.x < game.head.x, #left\n",
    "            game.food.y > game.head.y, #down\n",
    "        ]\n",
    "\n",
    "        # convert True false to 1, 0\n",
    "        return np.array(state, dtype = int)\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    \n",
    "    def train_long_memory(self):\n",
    "        if len(self.memory) > BATCH_SIZE:\n",
    "            sample = random.sample(self.memory, BATCH_SIZE) #returns list of tuples\n",
    "        else:\n",
    "            sample = self.memory\n",
    "\n",
    "    def train_short_memory(self, state, action, reward, next_state, done):\n",
    "        self.trainer.train_step(state, action, reward, next_state, done)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af18273774455bc90f5456b9f4898eab7ba4de506fde0c1d0784da333c7e8bbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
