{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.env import GridWorldRenderer, GridWorldEnv, GET_RANDOM_MAP\n",
    "from src.agent import QLearningAgent, SarsaAgent\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from src.utils import qtable_heatmap, agent_decision\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map = [\n",
    "#     ['A', 'R', '', 'S'],\n",
    "#     ['', '', '', ''],\n",
    "#     ['B', '', 'B', 'R'],\n",
    "#     ['', '', '', 'G']\n",
    "#     ]\n",
    "\n",
    "# rows = 4 \n",
    "# cols =4 \n",
    "\n",
    "# def gen_obj():\n",
    "#     choices = ['R', 'S', 'B', '-']\n",
    "#     weights =  [0.05, 0.05, 0.05, 0.85]\n",
    "#     return np.random.choice(choices, p = weights)\n",
    "\n",
    "# map = [[gen_obj() for _ in range(rows)] for _ in range(cols)]\n",
    "# map[0][0] = 'A'\n",
    "# map[rows - 1][cols - 1] = 'G'\n",
    "\n",
    "# map = [''.join(row) for row in map]\n",
    "\n",
    "# for row in map:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = [\n",
    "'A-B-BR---S---------S',\n",
    "'S-SB----RB-S-R--B---',\n",
    "'B----BB---------S-R-',\n",
    "'---------RB--R----S-',\n",
    "'RR------------S----S',\n",
    "'-------B------------',\n",
    "'-----R--S----------S',\n",
    "'-----R-----R----B---',\n",
    "'-S------S-------B---',\n",
    "'------R------R-R----',\n",
    "'-------B------------',\n",
    "'----------B--------B',\n",
    "'--S----B-----S------',\n",
    "'-R--------------BB--',\n",
    "'-------B-----------R',\n",
    "'-------S----R-----RB',\n",
    "'---R---------S--S---',\n",
    "'--------------SB----',\n",
    "'B-------------------',\n",
    "'--S---B--BSS-B----RG',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m      1\u001b[0m reward_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mterminated\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# map = [\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     \"A--B\",\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#     \"----\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# map = GET_RANDOM_MAP(20,20)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#print map\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mmap\u001b[39m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(row)\n\u001b[1;32m     20\u001b[0m env \u001b[38;5;241m=\u001b[39m GridWorldEnv(\u001b[38;5;28mmap\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m, reward_dict \u001b[38;5;241m=\u001b[39m reward_dict, max_timestep \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not iterable"
     ]
    }
   ],
   "source": [
    "reward_dict = {\n",
    "    'G': 3,\n",
    "    'B': 1,\n",
    "    'R': -1,\n",
    "    'S': -2,\n",
    "    'out_of_bound': -1,\n",
    "    'visited_state': -1,\n",
    "    'terminated': -1,\n",
    "}\n",
    "# map = [\n",
    "#     \"A--B\",\n",
    "#     \"----\",\n",
    "#     \"B---\",\n",
    "#     \"---G\",\n",
    "# ]\n",
    "# map = GET_RANDOM_MAP(20,20)\n",
    "#print map\n",
    "for row in map:\n",
    "    print(row)\n",
    "env = GridWorldEnv(map = map, reward_dict = reward_dict, max_timestep = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m agent \u001b[38;5;241m=\u001b[39m QLearningAgent(env, n_training_eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50000\u001b[39m, learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m, decay_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5e-5\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# agent.train()\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# agent.save()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# agent.load('./qtable.npy')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5c9a33fa\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "agent = QLearningAgent(env, n_training_eps = 50000, learning_rate = 0.01, decay_rate = 5e-5)\n",
    "# agent.train()\n",
    "# agent.save()\n",
    "# agent.load('./qtable.npy')\n",
    "id = '5c9a33fa'\n",
    "agent.load(id)\n",
    "print(agent.qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QLearningAgent' object has no attribute 'save_attempt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39msave_attempt()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'QLearningAgent' object has no attribute 'save_attempt'"
     ]
    }
   ],
   "source": [
    "id = agent.save_attempt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "ENV MAP\n",
      "====================\n",
      "['A', '-', 'B', '-', 'B', 'R', '-', '-', '-', 'S', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'S']\n",
      "['S', '-', 'S', 'B', '-', '-', '-', '-', 'R', 'B', '-', 'S', '-', 'R', '-', '-', 'B', '-', '-', '-']\n",
      "['B', '-', '-', '-', '-', 'B', 'B', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'S', '-', 'R', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', 'R', 'B', '-', '-', 'R', '-', '-', '-', '-', 'S', '-']\n",
      "['R', 'R', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'S', '-', '-', '-', '-', 'S']\n",
      "['-', '-', '-', '-', '-', '-', '-', 'B', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', 'R', '-', '-', 'S', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'S']\n",
      "['-', '-', '-', '-', '-', 'R', '-', '-', '-', '-', '-', 'R', '-', '-', '-', '-', 'B', '-', '-', '-']\n",
      "['-', 'S', '-', '-', '-', '-', '-', '-', 'S', '-', '-', '-', '-', '-', '-', '-', 'B', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', 'R', '-', '-', '-', '-', '-', '-', 'R', '-', 'R', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', 'B', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'B', '-', '-', '-', '-', '-', '-', '-', '-', 'B']\n",
      "['-', '-', 'S', '-', '-', '-', '-', 'B', '-', '-', '-', '-', '-', 'S', '-', '-', '-', '-', '-', '-']\n",
      "['-', 'R', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'B', 'B', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', 'B', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'R']\n",
      "['-', '-', '-', '-', '-', '-', '-', 'S', '-', '-', '-', '-', 'R', '-', '-', '-', '-', '-', 'R', 'B']\n",
      "['-', '-', '-', 'R', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'S', '-', '-', 'S', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'S', 'B', '-', '-', '-', '-']\n",
      "['B', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', 'S', '-', '-', '-', 'B', '-', '-', 'B', 'S', 'S', '-', 'B', '-', '-', '-', '-', 'R', 'G']\n",
      "====================\n",
      "ENV STATE\n",
      "====================\n",
      "[[1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.5]]\n",
      "====================\n",
      "ENV DESCRIPTION\n",
      "====================\n",
      "reward dict = {'G': 3, 'B': 1, 'R': -1, 'S': -2, 'out_of_bound': -1, 'visited_state': -1, 'terminated': -1}\n",
      "timestep = 0, max_timestep = 100,\n",
      "obs space = 400\n",
      "actions = 4\n",
      "agent position = [0, 0]\n",
      "goal position = [19, 19]\n",
      "terminated = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the enviroment rewards and stuff\n",
    "# info = env.step(2)\n",
    "# print(env.state)\n",
    "# for row in env.map:\n",
    "#     print(row)\n",
    "# print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.render_simple(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.render(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_attempt(map, qtable, id = None):\n",
    "    if id == None:\n",
    "        id = str(uuid.uuid4()).split('-')[0]\n",
    "    attemp_dir = f'./attempts/{id}'\n",
    "\n",
    "    if os.path.exists(attemp_dir) == False:\n",
    "        os.path.join(attemp_dir, f'attemp_{1}')\n",
    "        os.makedirs(attemp_dir)\n",
    "    map_path = os.path.join(attemp_dir,'map.json')\n",
    "    with open(map_path, 'w') as mapfile:\n",
    "        json.dump(map, mapfile)\n",
    "    \n",
    "    qtable_path = os.path.join(attemp_dir,'qtable.npy')\n",
    "    with open(qtable_path, 'wb') as qtablefile:\n",
    "        np.save(qtablefile, qtable)\n",
    "    return id\n",
    "\n",
    "def load_attempt(id):\n",
    "    attemp_dir = f'./attempts/{id}'\n",
    "    if os.path.exists(attemp_dir):\n",
    "\n",
    "        map_path = os.path.join(attemp_dir,'map.json')\n",
    "        with open(map_path, 'rb') as mapfile:\n",
    "            map = json.load(mapfile)\n",
    "        \n",
    "        qtable_path = os.path.join(attemp_dir,'qtable.npy')\n",
    "        with open(qtable_path, 'rb') as qtablefile:\n",
    "            qtable = np.load(qtablefile)\n",
    "        \n",
    "        return map, qtable\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"{attemp_dir} directory not found\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = save_attempt(map, agent.qtable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A-B-BR---S---------S', 'S-SB----RB-S-R--B---', 'B----BB---------S-R-', '---------RB--R----S-', 'RR------------S----S', '-------B------------', '-----R--S----------S', '-----R-----R----B---', '-S------S-------B---', '------R------R-R----', '-------B------------', '----------B--------B', '--S----B-----S------', '-R--------------BB--', '-------B-----------R', '-------S----R-----RB', '---R---------S--S---', '--------------SB----', 'B-------------------', '--S---B--BSS-B----RG']\n",
      "[[-0.64014482  0.38787197 -1.80258691 -0.6411766 ]\n",
      " [-0.39285859  0.68549678 -0.56247196  0.01869859]\n",
      " [-0.92983793  0.0493947  -2.00952037 -0.39513618]\n",
      " ...\n",
      " [ 1.65248637  1.85        0.75748632  0.75098627]\n",
      " [ 2.04667638  3.          1.84997202  1.06636825]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "map, qtable = load_attempt(id)\n",
    "print(map)\n",
    "print(qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "af18273774455bc90f5456b9f4898eab7ba4de506fde0c1d0784da333c7e8bbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
