{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.env import GridWorldRenderer, GridWorldEnv\n",
    "from src.agent import QLearningAgent\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map = [\n",
    "#     ['A', 'R', '', 'S'],\n",
    "#     ['', '', '', ''],\n",
    "#     ['B', '', 'B', 'R'],\n",
    "#     ['', '', '', 'G']\n",
    "#     ]\n",
    "\n",
    "# rows = 4 \n",
    "# cols =4 \n",
    "\n",
    "# def gen_obj():\n",
    "#     choices = ['R', 'S', 'B', '-']\n",
    "#     weights =  [0.05, 0.05, 0.05, 0.85]\n",
    "#     return np.random.choice(choices, p = weights)\n",
    "\n",
    "# map = [[gen_obj() for _ in range(rows)] for _ in range(cols)]\n",
    "# map[0][0] = 'A'\n",
    "# map[rows - 1][cols - 1] = 'G'\n",
    "\n",
    "# map = [''.join(row) for row in map]\n",
    "\n",
    "# for row in map:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_dict = {\n",
    "    'G': 10,\n",
    "    'B': 0,\n",
    "    'R': -1,\n",
    "    'S': -2,\n",
    "    'out-of-bound': -5,\n",
    "    'terminated': -3,\n",
    "}\n",
    "map = [\n",
    "    \"A---\",\n",
    "    \"----\",\n",
    "    \"BR--\",\n",
    "    \"---G\",\n",
    "]\n",
    "env = GridWorldEnv(map = map, reward_dict = reward_dict, max_timestep = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep = 45, eposilon = 0.98, reached goals = 40, terminated = 0:   0%|          | 27/10000 [00:00<00:42, 235.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "TRAINING\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep = 9999, eposilon = 0.01, reached goals = 9962, terminated = 0: 100%|██████████| 10000/10000 [00:17<00:00, 571.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.72615612  6.39429121  1.84856592 -1.78906748]\n",
      " [-1.07267963  7.31047399  3.85133389  2.75249927]\n",
      " [-0.15759753  4.2891763   8.16486842  3.408369  ]\n",
      " [-1.33924326 -1.35079315  7.89717182  2.24591361]\n",
      " [ 0.95839751  4.15001187  0.07794229 -3.0146295 ]\n",
      " [ 1.89656403  7.34320754  0.37696919  0.92551939]\n",
      " [ 4.61696195  8.87862704  4.95590416  3.88738165]\n",
      " [ 4.77050274  2.31322071  9.45415533  5.69671275]\n",
      " [ 0.17979524 -0.20622284  0.46186048 -2.29599608]\n",
      " [ 0.76844126  3.94204356  0.93918471  0.04328451]\n",
      " [ 2.99901103  4.89385606  8.14994263  0.25250755]\n",
      " [ 5.98495805  2.8913561   9.98690775  4.52109837]\n",
      " [ 0.02982089  1.91063232 -2.11818611 -2.18900016]\n",
      " [-0.09875942  5.7695121  -1.72897735  0.20947166]\n",
      " [ 2.59113863  9.64159065  0.86218838  1.82617068]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "agent = QLearningAgent(env)\n",
    "agent.train()\n",
    "agent.save()\n",
    "# agent.load('./qtable.npy')\n",
    "print(agent.qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "['A', '-', '-', '-']\n",
      "['-', '-', '-', '-']\n",
      "['B', 'R', '-', '-']\n",
      "['-', '-', '-', 'G']\n",
      "(15, 10, True, False, {})\n"
     ]
    }
   ],
   "source": [
    "#Test the enviroment rewards and stuff\n",
    "info = env.step(2)\n",
    "print(env.state)\n",
    "for row in env.map:\n",
    "    print(row)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "====================\n",
      "MAP\n",
      "['A', '-', '-', '-']\n",
      "['-', '-', '-', '-']\n",
      "['B', 'R', '-', '-']\n",
      "['-', '-', '-', 'G']\n",
      "====================\n",
      "took action =  1  to state  1 done = False\n",
      "[[0.  1.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "====================\n",
      "took action =  1  to state  2 done = False\n",
      "[[0.  0.  1.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "====================\n",
      "took action =  2  to state  6 done = False\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "====================\n",
      "took action =  1  to state  7 done = False\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "====================\n",
      "took action =  2  to state  11 done = False\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "====================\n",
      "took action =  2  to state  15 done = True\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "====================\n",
      "took action =  0  to state  11 done = True\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "====================\n",
      "took action =  2  to state  15 done = True\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "====================\n",
      "took action =  0  to state  11 done = True\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "====================\n",
      "took action =  2  to state  15 done = True\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "====================\n",
      "took action =  0  to state  11 done = True\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "====================\n",
      "took action =  2  to state  15 done = True\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "====================\n",
      "took action =  0  to state  11 done = True\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "====================\n",
      "took action =  2  to state  15 done = True\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.5]]\n",
      "====================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\ML\\ml_projects\\rl\\mainv2.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ML/ml_projects/rl/mainv2.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m env\u001b[39m.\u001b[39mreset()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ML/ml_projects/rl/mainv2.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(env\u001b[39m.\u001b[39mstate)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/ML/ml_projects/rl/mainv2.ipynb#X50sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m env\u001b[39m.\u001b[39;49mrender_simple(agent)\n",
      "File \u001b[1;32me:\\ML\\ml_projects\\rl\\src\\env.py:204\u001b[0m, in \u001b[0;36mGridWorldEnv.render_simple\u001b[1;34m(self, agent)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate)\n\u001b[0;32m    203\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m20\u001b[39m)\n\u001b[1;32m--> 204\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.5\u001b[39;49m)\n\u001b[0;32m    206\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdone = \u001b[39m\u001b[39m{\u001b[39;00mdone\u001b[39m}\u001b[39;00m\u001b[39m, terminated = \u001b[39m\u001b[39m{\u001b[39;00mterminated\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "print(env.state)\n",
    "env.render_simple(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
