{"cells":[{"cell_type":"markdown","metadata":{"id":"rfnoi2f6Nhe3"},"source":["# Following this series:\n","https://www.youtube.com/watch?v=t-phGBfPEZ4&list=PLhhyoLH6Ijfw0TpCTVTNk42NN08H6UvNq"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1700061887296,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"DCh1VxeJ1R_P"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n","  warnings.warn(_BETA_TRANSFORMS_WARNING)\n","c:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n","  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"]}],"source":["import torch.nn as nn\n","import torch\n","from torchinfo import summary\n","# from torchmetrics.detection import IntersectionOverUnion\n","from collections import *\n","# metrics from aladin peterson\n","# https://github.com/aladdinpersson/Machine-Learning-Collection\n","from utils.main import *\n","import os\n","import pandas as pd\n","import PIL as image\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import v2, ToTensor"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1700058991909,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"kKxBH_QvvZ0I"},"outputs":[],"source":["cnn_config = [\n","  # kernel, filter, stride, padding\n","  (7,64,2,3),\n","  # max pool\n","  \"M\",\n","  (3,192,1,1),\n","  \"M\",\n","  (1,128,1,0),\n","  (3,256,1,0),\n","  (3,256,1,0),\n","  (3,512,1,1),\n","  \"M\",\n","  #CNN block with 4 identical layers\n","  [(1,256,1,0), (3,512,1,1), 4],\n","  (1,512,1,0),\n","  (3,1024,1,1),\n","  \"M\",\n","  [(1,512,1,0), (3,1024, 1,1), 2],\n","  (3,1024,1,1),\n","  (3,1024,2,1),\n","  (3,1024,1,1),\n","  (3,1024,1,1),\n","]\n","\n","class CNNBlock(nn.Module):\n","  def __init__(self, out_channels, **kwargs):\n","    super(CNNBlock, self).__init__()\n","    #turn of bias to use BatchNorm\n","    self.conv = nn.LazyConv2d(out_channels, bias= False, **kwargs)\n","    self.batchnorm = nn.BatchNorm2d(num_features = out_channels)\n","    self.leaky_relu = nn.LeakyReLU(0.1)\n","\n","  def forward(self, X):\n","    return self.leaky_relu(self.batchnorm(self.conv(X)))\n","\n","class Yolov1(nn.Module):\n","  def __init__(self, **kwargs):\n","    super(Yolov1, self).__init__()\n","    self.cnn_config = cnn_config\n","    # self.in_channels = in_channels\n","    #pass in the cnn config to construct the model\n","    self.darknet = self._create_conv_layers(self.cnn_config)\n","    #fully connected layer creation\n","    self.fc = self._create_fc(**kwargs)\n","\n","  def forward(self, X):\n","    X = self.darknet(X)\n","    return self.fc(torch.flatten(X, start_dim=1))\n","\n","  def _create_conv_layers(self, config):\n","    layers = []\n","    # in_channels = self.in_channels\n","\n","    for x in config:\n","      #conv layer\n","      if type(x) == tuple:\n","        kernel, out_channels, stride, padding = x\n","        layers.append(CNNBlock(out_channels,\n","                               kernel_size = kernel, stride = stride, padding = padding))\n","      elif type(x) == str:\n","        layers.append(nn.MaxPool2d(kernel_size = (2,2), stride = (2,2)))\n","\n","      elif type(x) == list:\n","        conv1, conv2, repeats = x\n","        for _ in range(repeats):\n","          kernel1, out_channels1, stride1, padding1 = conv1\n","          layers.append(CNNBlock(out_channels1,\n","                                kernel_size = kernel1, stride = stride1, padding = padding1))\n","\n","          kernel2, out_channels2, stride2, padding2 = conv2\n","          layers.append(CNNBlock(out_channels2,\n","                                kernel_size = kernel2, stride = stride2, padding = padding2))\n","          #according to the paper, for each repeated block, we take output channel of conv2\n","          #and feed it as in channel to the next block\n","          # in_channels = out_channels2\n","    #unpack a list [a,b,c,d,...] into a,b,c,d,...\n","    return nn.Sequential(*layers)\n","\n","\n","  def _create_fc(self, grid_size, num_boxes, num_classes):\n","    # pred vector should look like [c1,c2,...cN, p1, x1,y1,w1,h2, p2, x2,y2,w2,h2]\n","    S, B, C = grid_size, num_boxes, num_classes\n","\n","    return nn.Sequential(\n","        nn.Flatten(),\n","        nn.LazyLinear(496), # original paper is 4096, reduce it to reduce training resources\n","        nn.Dropout(0.5),\n","        nn.LeakyReLU(0.1),\n","        #each cell has # of classes + # of boxes * 5 (5 because it's p,x,y,w,h)\n","        nn.Linear(496, S * S * (C + B * 5)), #Reshape to (S*S * 30)\n","    )\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5822,"status":"ok","timestamp":1700058997714,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"6Uwij8p01mot","outputId":"caa4c9e0-40a0-41f0-89f4-28d7c00bb2d2"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n","  warnings.warn('Lazy modules are a new feature under heavy development '\n"]},{"data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","Yolov1                                   [2, 1470]                 --\n","├─Sequential: 1-1                        [2, 1024, 7, 7]           --\n","│    └─CNNBlock: 2-1                     [2, 64, 224, 224]         --\n","│    │    └─Conv2d: 3-1                  [2, 64, 224, 224]         9,408\n","│    │    └─BatchNorm2d: 3-2             [2, 64, 224, 224]         128\n","│    │    └─LeakyReLU: 3-3               [2, 64, 224, 224]         --\n","│    └─MaxPool2d: 2-2                    [2, 64, 112, 112]         --\n","│    └─CNNBlock: 2-3                     [2, 192, 112, 112]        --\n","│    │    └─Conv2d: 3-4                  [2, 192, 112, 112]        110,592\n","│    │    └─BatchNorm2d: 3-5             [2, 192, 112, 112]        384\n","│    │    └─LeakyReLU: 3-6               [2, 192, 112, 112]        --\n","│    └─MaxPool2d: 2-4                    [2, 192, 56, 56]          --\n","│    └─CNNBlock: 2-5                     [2, 128, 56, 56]          --\n","│    │    └─Conv2d: 3-7                  [2, 128, 56, 56]          24,576\n","│    │    └─BatchNorm2d: 3-8             [2, 128, 56, 56]          256\n","│    │    └─LeakyReLU: 3-9               [2, 128, 56, 56]          --\n","│    └─CNNBlock: 2-6                     [2, 256, 54, 54]          --\n","│    │    └─Conv2d: 3-10                 [2, 256, 54, 54]          294,912\n","│    │    └─BatchNorm2d: 3-11            [2, 256, 54, 54]          512\n","│    │    └─LeakyReLU: 3-12              [2, 256, 54, 54]          --\n","│    └─CNNBlock: 2-7                     [2, 256, 52, 52]          --\n","│    │    └─Conv2d: 3-13                 [2, 256, 52, 52]          589,824\n","│    │    └─BatchNorm2d: 3-14            [2, 256, 52, 52]          512\n","│    │    └─LeakyReLU: 3-15              [2, 256, 52, 52]          --\n","│    └─CNNBlock: 2-8                     [2, 512, 52, 52]          --\n","│    │    └─Conv2d: 3-16                 [2, 512, 52, 52]          1,179,648\n","│    │    └─BatchNorm2d: 3-17            [2, 512, 52, 52]          1,024\n","│    │    └─LeakyReLU: 3-18              [2, 512, 52, 52]          --\n","│    └─MaxPool2d: 2-9                    [2, 512, 26, 26]          --\n","│    └─CNNBlock: 2-10                    [2, 256, 26, 26]          --\n","│    │    └─Conv2d: 3-19                 [2, 256, 26, 26]          131,072\n","│    │    └─BatchNorm2d: 3-20            [2, 256, 26, 26]          512\n","│    │    └─LeakyReLU: 3-21              [2, 256, 26, 26]          --\n","│    └─CNNBlock: 2-11                    [2, 512, 26, 26]          --\n","│    │    └─Conv2d: 3-22                 [2, 512, 26, 26]          1,179,648\n","│    │    └─BatchNorm2d: 3-23            [2, 512, 26, 26]          1,024\n","│    │    └─LeakyReLU: 3-24              [2, 512, 26, 26]          --\n","│    └─CNNBlock: 2-12                    [2, 256, 26, 26]          --\n","│    │    └─Conv2d: 3-25                 [2, 256, 26, 26]          131,072\n","│    │    └─BatchNorm2d: 3-26            [2, 256, 26, 26]          512\n","│    │    └─LeakyReLU: 3-27              [2, 256, 26, 26]          --\n","│    └─CNNBlock: 2-13                    [2, 512, 26, 26]          --\n","│    │    └─Conv2d: 3-28                 [2, 512, 26, 26]          1,179,648\n","│    │    └─BatchNorm2d: 3-29            [2, 512, 26, 26]          1,024\n","│    │    └─LeakyReLU: 3-30              [2, 512, 26, 26]          --\n","│    └─CNNBlock: 2-14                    [2, 256, 26, 26]          --\n","│    │    └─Conv2d: 3-31                 [2, 256, 26, 26]          131,072\n","│    │    └─BatchNorm2d: 3-32            [2, 256, 26, 26]          512\n","│    │    └─LeakyReLU: 3-33              [2, 256, 26, 26]          --\n","│    └─CNNBlock: 2-15                    [2, 512, 26, 26]          --\n","│    │    └─Conv2d: 3-34                 [2, 512, 26, 26]          1,179,648\n","│    │    └─BatchNorm2d: 3-35            [2, 512, 26, 26]          1,024\n","│    │    └─LeakyReLU: 3-36              [2, 512, 26, 26]          --\n","│    └─CNNBlock: 2-16                    [2, 256, 26, 26]          --\n","│    │    └─Conv2d: 3-37                 [2, 256, 26, 26]          131,072\n","│    │    └─BatchNorm2d: 3-38            [2, 256, 26, 26]          512\n","│    │    └─LeakyReLU: 3-39              [2, 256, 26, 26]          --\n","│    └─CNNBlock: 2-17                    [2, 512, 26, 26]          --\n","│    │    └─Conv2d: 3-40                 [2, 512, 26, 26]          1,179,648\n","│    │    └─BatchNorm2d: 3-41            [2, 512, 26, 26]          1,024\n","│    │    └─LeakyReLU: 3-42              [2, 512, 26, 26]          --\n","│    └─CNNBlock: 2-18                    [2, 512, 26, 26]          --\n","│    │    └─Conv2d: 3-43                 [2, 512, 26, 26]          262,144\n","│    │    └─BatchNorm2d: 3-44            [2, 512, 26, 26]          1,024\n","│    │    └─LeakyReLU: 3-45              [2, 512, 26, 26]          --\n","│    └─CNNBlock: 2-19                    [2, 1024, 26, 26]         --\n","│    │    └─Conv2d: 3-46                 [2, 1024, 26, 26]         4,718,592\n","│    │    └─BatchNorm2d: 3-47            [2, 1024, 26, 26]         2,048\n","│    │    └─LeakyReLU: 3-48              [2, 1024, 26, 26]         --\n","│    └─MaxPool2d: 2-20                   [2, 1024, 13, 13]         --\n","│    └─CNNBlock: 2-21                    [2, 512, 13, 13]          --\n","│    │    └─Conv2d: 3-49                 [2, 512, 13, 13]          524,288\n","│    │    └─BatchNorm2d: 3-50            [2, 512, 13, 13]          1,024\n","│    │    └─LeakyReLU: 3-51              [2, 512, 13, 13]          --\n","│    └─CNNBlock: 2-22                    [2, 1024, 13, 13]         --\n","│    │    └─Conv2d: 3-52                 [2, 1024, 13, 13]         4,718,592\n","│    │    └─BatchNorm2d: 3-53            [2, 1024, 13, 13]         2,048\n","│    │    └─LeakyReLU: 3-54              [2, 1024, 13, 13]         --\n","│    └─CNNBlock: 2-23                    [2, 512, 13, 13]          --\n","│    │    └─Conv2d: 3-55                 [2, 512, 13, 13]          524,288\n","│    │    └─BatchNorm2d: 3-56            [2, 512, 13, 13]          1,024\n","│    │    └─LeakyReLU: 3-57              [2, 512, 13, 13]          --\n","│    └─CNNBlock: 2-24                    [2, 1024, 13, 13]         --\n","│    │    └─Conv2d: 3-58                 [2, 1024, 13, 13]         4,718,592\n","│    │    └─BatchNorm2d: 3-59            [2, 1024, 13, 13]         2,048\n","│    │    └─LeakyReLU: 3-60              [2, 1024, 13, 13]         --\n","│    └─CNNBlock: 2-25                    [2, 1024, 13, 13]         --\n","│    │    └─Conv2d: 3-61                 [2, 1024, 13, 13]         9,437,184\n","│    │    └─BatchNorm2d: 3-62            [2, 1024, 13, 13]         2,048\n","│    │    └─LeakyReLU: 3-63              [2, 1024, 13, 13]         --\n","│    └─CNNBlock: 2-26                    [2, 1024, 7, 7]           --\n","│    │    └─Conv2d: 3-64                 [2, 1024, 7, 7]           9,437,184\n","│    │    └─BatchNorm2d: 3-65            [2, 1024, 7, 7]           2,048\n","│    │    └─LeakyReLU: 3-66              [2, 1024, 7, 7]           --\n","│    └─CNNBlock: 2-27                    [2, 1024, 7, 7]           --\n","│    │    └─Conv2d: 3-67                 [2, 1024, 7, 7]           9,437,184\n","│    │    └─BatchNorm2d: 3-68            [2, 1024, 7, 7]           2,048\n","│    │    └─LeakyReLU: 3-69              [2, 1024, 7, 7]           --\n","│    └─CNNBlock: 2-28                    [2, 1024, 7, 7]           --\n","│    │    └─Conv2d: 3-70                 [2, 1024, 7, 7]           9,437,184\n","│    │    └─BatchNorm2d: 3-71            [2, 1024, 7, 7]           2,048\n","│    │    └─LeakyReLU: 3-72              [2, 1024, 7, 7]           --\n","├─Sequential: 1-2                        [2, 1470]                 --\n","│    └─Flatten: 2-29                     [2, 50176]                --\n","│    └─Linear: 2-30                      [2, 496]                  24,887,792\n","│    └─Dropout: 2-31                     [2, 496]                  --\n","│    └─LeakyReLU: 2-32                   [2, 496]                  --\n","│    └─Linear: 2-33                      [2, 1470]                 730,590\n","==========================================================================================\n","Total params: 86,311,822\n","Trainable params: 86,311,822\n","Non-trainable params: 0\n","Total mult-adds (G): 38.54\n","==========================================================================================\n","Input size (MB): 4.82\n","Forward/backward pass size (MB): 409.70\n","Params size (MB): 345.25\n","Estimated Total Size (MB): 759.76\n","=========================================================================================="]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["S = 7\n","B = 2\n","C = 20\n","\n","model = Yolov1(grid_size = S, num_boxes = B, num_classes = C)\n","summary(model, input_size=(2,3,448,448))"]},{"cell_type":"markdown","metadata":{},"source":["# Loss function\n","check formula in the paper"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"LAgBF4CtHJXF"},"outputs":[],"source":["# The idea of this is each prediction gives 2 boxes\n","# There's only 1 box for target\n","# then get IoU of these 2 pred boxes on 1 target box\n","\n","class YoloLoss(nn.Module):\n","  def __init__(self, S= 7,B = 2, C = 30):\n","    super(YoloLoss, self).__init__()\n","\n","    self.mse = nn.MSELoss(reduction = 'sum')\n","    self.S = S\n","    self.B = B\n","    self.C = C\n","    self.lambda_noobj = 0.5\n","    self.lambda_coord = 5\n","\n","  def forward(self, preds, target):\n","    #Input shape = 2 * 1470 ( from summary above)\n","    # Reshape to (-1, S, S, C + B * 5)\n","    #Preds = [c1,c2,...c20, p1, x1, y2, w1, h1, p2, x2, y2, w2, h2]\n","\n","    preds = preds.reshape(-1, self.S, self.S, self.C + self.B * 5)\n","    box1 = preds[...]\n","    # 21:25 is the first box x1,y1,w1,h1\n","    iou_box1 = intersection_over_union(preds[..., 21:25], target[..., 21:25])\n","    # 26:30 is the 2nd box x2,y2,w2,h2\n","    iou_box2 = intersection_over_union(preds[..., 26:30], target[..., 21:25])\n","\n","    #torch.squeeze: insert new dimension to that specify position\n","    ious = torch.cat([iou_box1.unsqueeze(0), iou_box2.unsqueeze(0)], dim = 0)\n","    iou_max, bestbox = torch.max(ious, dim = 0)\n","    #exists box, 1 or 0\n","    exists_box = target[..., 20].unsqueeze(3)\n","    #box coords\n","\n","    box_preds = exists_box * (bestbox * (preds[..., 26:30]) + \\\n","                              (1 - bestbox) * (preds[..., 21:25]))\n","    box_targets = exists_box * target[..., 21 : 25]\n","\n","    #the 1e-6 is for numerical stability\n","    # torch.sign([-1,-0.5, 1, 0.5, 0]) --> [-1,-1, 1, 1, 0]\n","    box_preds[..., 2:4] = torch.sign(box_preds[..., 2:4]) * \\\n","      torch.sqrt(torch.abs(box_preds[..., 2:4] + 1e-6))\n","\n","    box_targets[..., 2:4] = torch.sqrt(box_targets[..., 2:4])\n","\n","    #Flatten the first 3 dims, input (N, S, S, 4) --> (N * S * S, 4)\n","    box_loss = self.mse(\n","         torch.flatten(box_preds, end_dim = -2),\n","         torch.flatten(box_targets, end_dim = -2),\n","    )\n","\n","    #object loss\n","    # pred box shape = (N * S * S, 1)\n","    pred_box = (\n","        bestbox * preds[..., 25:26] + (1 - bestbox) * preds[..., 20:21]\n","    )\n","\n","    object_loss = self.mse(\n","      torch.flatten(exists_box * pred_box),\n","      torch.flatten(exists_box * target[..., 20:21]),\n","    )\n","\n","    #no object loss\n","    # (N,S,S,1) --> (N, S * S)\n","    noobject_loss = self.mse(\n","      torch.flatten((1 - exists_box) * preds[..., 20:21], start_dim=1),\n","      torch.flatten((1 - exists_box) * target[..., 20:21], start_dim=1)\n","    )\n","    noobject_loss += self.mse(\n","      torch.flatten((1 - exists_box) * preds[..., 25:26], start_dim=1),\n","      torch.flatten((1 - exists_box) * target[..., 20:21], start_dim=1)\n","    )\n","\n","    #class loss\n","    # (N, S, S, 20) --> (N *S * S, 20)\n","    class_loss = self.mse(\n","      torch.flatten(exists_box * preds[..., :20], end_dim = -2),\n","      torch.flatten(exists_box * target[..., :20], end_dim = -2)\n","    )\n","\n","    loss = (\n","      self.lambda_coord * box_loss\\\n","      + object_loss\n","      + self.lambda_noobj * noobject_loss\n","      + class_loss\n","    )\n","\n","    return loss\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Loading the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["class VOCDataset(Dataset):\n","    def __init__(self, csv_file, img_dir, label_dir, S = 7, B = 2, C = 20, transforms = None):\n","        self.annotations = pd.read_csv(csv_file)\n","        self.img_dir = img_dir\n","        self.label_dir = label_dir\n","        self.S = S\n","        self.B = B\n","        self.C = C\n","    \n","    def __len__(self):\n","        return len(self.annotations)\n","    \n","    def __getitem__(self, index):\n","        label_path = os.path.join(self.label_dir, self.annotations.iloc[index,1])\n","        print(label_path)\n","\n","VOC_PATH = './data/'\n","VOC_IMAGE_PATH = './data/images/'\n","VOC_LABEL_PATH = './data/labels/'\n","\n","TRAIN_VOC_CSV = os.path.join(VOC_PATH, 'train.csv')\n","voc = VOCDataset(TRAIN_VOC_CSV, VOC_IMAGE_PATH, VOC_LABEL_PATH)\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["./data/labels/000007.txt\n","None\n"]}],"source":["print(voc[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700064342737,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"zxJqm-aXYB9z"},"outputs":[],"source":["# def IoU(box_preds, box_labels, box_format = \"midpoint\"):\n","\n","#   if box_format == 'midpoint':\n","#     box1_x1 = box_preds[..., 0:1] - box_preds[..., 2:3] / 2\n","#     box1_y1 = box_preds[..., 1:2] - box_preds[..., 3:4] / 2\n","#     box1_x2 = box_preds[..., 0:1] + box_preds[..., 2:3] / 2\n","#     box1_y2 = box_preds[..., 1:2] + box_preds[..., 3:4] / 2\n","\n","#     box2_x1 = box_labels[..., 0:1] - box_labels[..., 2:3] / 2\n","#     box2_y1 = box_labels[..., 1:2] - box_labels[..., 3:4] / 2\n","#     box2_x2 = box_labels[..., 0:1] + box_labels[..., 2:3] / 2\n","#     box2_y2 = box_labels[..., 1:2] + box_labels[..., 3:4] / 2\n","#   else:\n","#     box1_x1 = box_preds[..., 0:1]\n","#     box1_y1 = box_preds[..., 1:2]\n","#     box1_x2 = box_preds[..., 2:3]\n","#     box1_y2 = box_preds[..., 3:4]\n","#     box2_x1 = box_labels[..., 0:1]\n","#     box2_y1 = box_labels[..., 1:2]\n","#     box2_x2 = box_labels[..., 2:3]\n","#     box2_y2 = box_labels[..., 3:4]\n","\n","#   x1 = torch.max(box1_x1, box2_x1)\n","#   y1 = torch.max(box1_y1, box2_y1)\n","#   x2 = torch.min(box1_x2, box2_x2)\n","#   y2 = torch.min(box2_y2, box2_y2)\n","\n","#   #if x2 - x1 < 0 or y2 - y1 < 0, set intersection to 0\n","#   intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n","\n","#   box1_area = abs((box1_x2 - box1_x1) * (box1_y1 - box1_y2))\n","#   box2_area = abs((box2_x2 - box2_x1) * (box2_y1 - box2_y2))\n","\n","#   return intersection / (box1_area + box2_area)\n"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1700064349246,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"U6CNWH-BiQXg"},"outputs":[],"source":["# def no_max_supression(bbox, iou_threshold, threshold, box_format = 'midpoint'):\n","#   #pred format (1, 0.9, x1, y1, x2, y2)\n","#   # where 1 is the 0,1 value,1 means there's an object in this bbox, else 0\n","#   # 0.9 is the probability of this box\n","#   assert type(bbox) == list\n","#   bbox = [box for box in bbox if box[1] > threshold]\n","#   bbox = sorted(bbox, key = lambda x: x[1], reverse = True)\n","#   bbox_after_nms = []\n","\n","#   while bbox:\n","#     chosen_box = bbox.pop(0)\n","\n","#     bbox = [\n","#         box for box in bbox if box[0] != chosen_box[0]\\\n","#         or IoU(torch.tensor(chosen_box[2:]), torch.tensor(box[2:]), box_format = box_format) < iou_threshold\n","#     ]\n","\n","#     bbox_after_nms.append(chosen_box)\n","\n","#   return bbox_after_nms\n","\n"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700064807230,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"duTRWFMdkt51"},"outputs":[],"source":["# # Mean Average Precision as metric\n","# def mAP(pred_boxes, true_boxes, iou_threshold =0.5, box_format = 'midpoint', num_classes = 20):\n","#   average_precisions = []\n","#   #for numerical stability in float\n","#   epsilon = 1e-6\n","\n","#   #pred boxes(list): [[train_idx, class_pred, prob_score, x1, y1, x2, y2], ....]\n","#   #same for true boxes\n","#   for c in range(num_classes):\n","#     detections = []\n","#     ground_truths = []\n","\n","#     #only choose pred and true for that class\n","#     for pred_box in pred_boxes:\n","#       if pred_box[1] == c:\n","#         detections.append(pred_box)\n","#     for true_box in true_boxes:\n","#       if true_box[1] == c:\n","#         ground_truths.append(true_box)\n","\n","#     #img0 has 3 bboxes\n","#     #img1 has 5 bboxes\n","#     #convert to dictionary: amount_bboxes = {0:3, 1:5}\n","#     amount_bboxes = Counter([gt[0] for gt in ground_truths])\n","\n","#     #convert to dictionary with tensors:\n","#     #amount_bboxes = {0: tensor([0,0,0]), 1:tensor([0,0,0,0,0])}\n","#     #we're doing this because we gonna mark only 1 box in that image as true\n","#     #the other images are FP\n","#     for key, val in amount_bboxes.item():\n","#       amount_bboxes[key] = torch.zeros(val)\n","\n","#     detections.sort(key = lambda x: x[2], reverse = True)\n","#     TP = torch.zeros(len(detections))\n","#     FP = torch.zeros(len(detections))\n","\n","#     total_true_boxes = len(ground_truths)\n","\n","#     for detection_idx, detection in enumerate(detections):\n","#       #get the ground truth with the same id with the detected box\n","#       ground_truth_img = [ bbox for bbox in ground_truths if bbox[0] == detection[0]]\n","\n","#       num_ground_truths = len(ground_truth_img)\n","#       best_iou = 0\n","#       best_gt_idx = 0\n","\n","#       for idx, gt in enumerate(ground_truth_img):\n","#         iou = IoU(torch.tensor(detection[3:]), torch.tensor(ground_truths[3:]), box_format= box_format)\n","\n","#         if iou > best_iou:\n","#           best_iou = iou\n","#           best_gt_idx = idx\n","\n","#       if best_iou > iou_threshold:\n","#         if amount_bboxes[detection[0]][best_gt_idx] == 0:\n","#           TP[detection_idx] = 1\n","#           amount_bboxes[detection[0]][best_gt_idx] = 1\n","#         else:\n","#           FP[detection_idx] = 1\n","#       else:\n","#           FP[detection_idx] = 1\n","\n","#       # [1,1,0,1,1,0] --> [1,2,2,3,4,4]\n","#       TP_cumsum = torch.cumsum(TP, dim = 0)\n","#       FP_cumsum = torch.cumsum(FP, dim = 0)\n","\n","#       recalls = TP_cumsum / (total_true_boxes + epsilon)\n","#       precisions = torch.divide(TP_cumsum, (TP_cumsum + FP_cumsum + epsilon))\n","#       precisions = torch.cat(torch.tensor([1]), precisions)\n","\n","#       recalls = torch.cat((torch.tensor([0])), recalls)\n","\n","#       average_precisions.append(torch.trapz(precisions, recalls))\n","\n","#     return  sum(average_precisions) / len(average_precisions)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":133,"status":"ok","timestamp":1699283096684,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"JYVDoem8J0BH","outputId":"f5f1af8c-ae9b-4762-ac7f-31f4852e1510"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 1470])\n","torch.Size([2, 7, 7, 30])\n"]}],"source":["X = torch.randn((2,1470))\n","print(X.shape)\n","X = X.reshape(-1, 7,7, 30)\n","print(X.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":249,"status":"error","timestamp":1699284014757,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"sKW8WQs6MipS","outputId":"efcfbd9c-634c-472b-ea31-e7e332c1c7c3"},"outputs":[{"ename":"IndexError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-73-80c1851673be>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"]}],"source":["a = torch.tensor([list(range(30)) for _ in range(5)])\n","\n","print(a[..., 20].unsqueeze(2))\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNcI6xs3VG6o3MEVB1qsNdC","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
